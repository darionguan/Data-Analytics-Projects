{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "938f69e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import pandasql as psql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1567a152",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_abb_dict = {'Alabama': 'AL',\n",
    "                  'Alaska': 'AK',\n",
    "                  'Arizona': 'AZ',\n",
    "                  'Arkansas': 'AR',\n",
    "                  'California': 'CA',\n",
    "                  'Colorado': 'CO',\n",
    "                  'Connecticut': 'CT',\n",
    "                  'Delaware': 'DE',\n",
    "                  'DC': 'DC',\n",
    "                  'Florida': 'FL',\n",
    "                  'Georgia': 'GA',\n",
    "                  'Hawaii': 'HI',\n",
    "                  'Idaho': 'ID',\n",
    "                  'Illinois': 'IL',\n",
    "                  'Indiana': 'IN',\n",
    "                  'Iowa': 'IA',\n",
    "                  'Kansas': 'KS',\n",
    "                  'Kentucky': 'KY',\n",
    "                  'Louisiana': 'LA',\n",
    "                  'Maine': 'ME',\n",
    "                  'Maryland': 'MD',\n",
    "                  'Massachusetts': 'MA',\n",
    "                  'Michigan': 'MI',\n",
    "                  'Minnesota': 'MN',\n",
    "                  'Mississippi': 'MS',\n",
    "                  'Missouri': 'MO',\n",
    "                  'Montana': 'MT',\n",
    "                  'Nebraska': 'NE',\n",
    "                  'Nevada': 'NV',\n",
    "                  'NewHampshire': 'NH',\n",
    "                  'NewJersey': 'NJ',\n",
    "                  'NewMexico': 'NM',\n",
    "                  'NewYork': 'NY',\n",
    "                  'NorthCarolina': 'NC',\n",
    "                  'NorthDakota': 'ND',\n",
    "                  'Ohio': 'OH',\n",
    "                  'Oklahoma': 'OK',\n",
    "                  'Oregon': 'OR',\n",
    "                  'Pennsylvania': 'PA',\n",
    "                  'RhodeIsland': 'RI',\n",
    "                  'SouthCarolina': 'SC',\n",
    "                  'SouthDakota': 'SD',\n",
    "                  'Tennessee': 'TN',\n",
    "                  'Texas': 'TX',\n",
    "                  'Utah': 'UT',\n",
    "                  'Vermont': 'VT',\n",
    "                  'Virginia': 'VA',\n",
    "                  'Washington': 'WA',\n",
    "                  'WestVirginia': 'WV',\n",
    "                  'Wisconsin': 'WI',\n",
    "                  'Wyoming': 'WY'}\n",
    "\n",
    "fips_dict = {'Alabama': '01',\n",
    "              'Alaska': '02',\n",
    "              'Arizona': '04',\n",
    "              'Arkansas': '05',\n",
    "              'California': '06',\n",
    "              'Colorado': '08',\n",
    "              'Connecticut': '09',\n",
    "              'Delaware': '10',\n",
    "              'DC': '11',\n",
    "              'Florida': '12',\n",
    "              'Georgia': '13',\n",
    "              'Hawaii': '15',\n",
    "              'Idaho': '16',\n",
    "              'Illinois': '17',\n",
    "              'Indiana': '18',\n",
    "              'Iowa': '19',\n",
    "              'Kansas': '20',\n",
    "              'Kentucky': '21',\n",
    "              'Louisiana': '22',\n",
    "              'Maine': '23',\n",
    "              'Maryland': '24',\n",
    "              'Massachusetts': '25',\n",
    "              'Michigan': '26',\n",
    "              'Minnesota': '27',\n",
    "              'Mississippi': '28',\n",
    "              'Missouri': '29',\n",
    "              'Montana': '30',\n",
    "              'Nebraska': '31',\n",
    "              'Nevada': '32',\n",
    "              'NewHampshire': '33',\n",
    "              'NewJersey': '34',\n",
    "              'NewMexico': '35',\n",
    "              'NewYork': '36',\n",
    "              'NorthCarolina': '37',\n",
    "              'NorthDakota': '38',\n",
    "              'Ohio': '39',\n",
    "              'Oklahoma': '40',\n",
    "              'Oregon': '41',\n",
    "              'Pennsylvania': '42',\n",
    "              'RhodeIsland': '44',\n",
    "              'SouthCarolina': '45',\n",
    "              'SouthDakota': '46',\n",
    "              'Tennessee': '47',\n",
    "              'Texas': '48',\n",
    "              'Utah': '49',\n",
    "              'Vermont': '50',\n",
    "              'Virginia': '51',\n",
    "              'Washington': '53',\n",
    "              'WestVirginia': '54',\n",
    "              'Wisconsin': '55',\n",
    "              'Wyoming': '56'}\n",
    "\n",
    "state_dict = {'Alabama': 7,\n",
    "              'Arizona': 9,\n",
    "              'Arkansas': 4,\n",
    "              'California': 53,\n",
    "              'Colorado': 8,\n",
    "              'Connecticut': 5,\n",
    "              'Florida': 27,\n",
    "              'Georgia': 14,\n",
    "              'Hawaii': 2,\n",
    "              'Idaho': 2,\n",
    "              'Illinois': 18,\n",
    "              'Indiana': 9,\n",
    "              'Iowa': 4,\n",
    "              'Kansas': 4,\n",
    "              'Kentucky': 6,\n",
    "              'Louisiana': 6,\n",
    "              'Maine': 2,\n",
    "              'Maryland': 8,\n",
    "              'Massachusetts': 9,\n",
    "              'Michigan': 14,\n",
    "              'Minnesota': 8,\n",
    "              'Mississippi': 4,\n",
    "              'Missouri': 8,\n",
    "              'Nebraska': 3,\n",
    "              'Nevada': 4,\n",
    "              'NewHampshire': 2,\n",
    "              'NewJersey': 12,\n",
    "              'NewMexico': 3,\n",
    "              'NewYork': 27,\n",
    "              'NorthCarolina': 13,\n",
    "              'Ohio': 16,\n",
    "              'Oklahoma': 5,\n",
    "              'Oregon': 5,\n",
    "              'Pennsylvania': 18,\n",
    "              'RhodeIsland': 2,\n",
    "              'SouthCarolina': 7,\n",
    "              'Tennessee': 9,\n",
    "              'Texas': 36,\n",
    "              'Utah': 4,\n",
    "              'Virginia': 11,\n",
    "              'Washington': 10,\n",
    "              'WestVirginia': 3,\n",
    "              'Wisconsin': 8}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf04325f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make an empty dataframe\n",
    "def create_df():\n",
    "    dtypes = np.dtype(\n",
    "        [\n",
    "            ('State', object),\n",
    "            ('STATE_ABB', object),\n",
    "            ('FIPS', object),\n",
    "            ('CD', object),\n",
    "            ('Median household income', object),\n",
    "            ('Median nonfamily income', object),\n",
    "            ('Persons aged 18 to 64 in poverty', object),\n",
    "            ('Persons over 65 in poverty', object),\n",
    "            ('Unemployed civilians', object),\n",
    "            ('Less than 9th grade', object),\n",
    "            ('9th to 12th grade, no diploma', object),\n",
    "            ('High school graduate (includes equivalency)', object),\n",
    "            ('Some college, no degree', object),\n",
    "            ('Associates degree', object),\n",
    "            ('Bachelors degree', object),\n",
    "            ('Graduate or professional degree', object)\n",
    "        ]\n",
    "    )\n",
    "    acs_final_df = pd.DataFrame(np.empty(0, dtype=dtypes))\n",
    "    return acs_final_df\n",
    "\n",
    "def new_arr(num_cd):\n",
    "    districts = num_cd\n",
    "    i = 0\n",
    "    arr = []\n",
    "    while i < (districts + 1) * 3 + 1:\n",
    "        arr.append(i)\n",
    "        i += 1\n",
    "    return arr\n",
    "\n",
    "def file_to_state(filename):\n",
    "    text = filename\n",
    "    new_text = text[0:10] + '(.*)' + text[-4:]\n",
    "    result = re.search(new_text, text)\n",
    "    return result.group(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f43aefcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATE_ABB</th>\n",
       "      <th>FIPS</th>\n",
       "      <th>CD</th>\n",
       "      <th>Median household income</th>\n",
       "      <th>Median nonfamily income</th>\n",
       "      <th>Less than 9th grade</th>\n",
       "      <th>9th to 12th grade, no diploma</th>\n",
       "      <th>High school graduate (includes equivalency)</th>\n",
       "      <th>Some college, no degree</th>\n",
       "      <th>Associates degree</th>\n",
       "      <th>Bachelors degree</th>\n",
       "      <th>Graduate or professional degree</th>\n",
       "      <th>Persons aged 18 to 64 in poverty</th>\n",
       "      <th>Persons over 65 in poverty</th>\n",
       "      <th>Unemployed civilians</th>\n",
       "      <th>State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AK</td>\n",
       "      <td>02</td>\n",
       "      <td>01</td>\n",
       "      <td>75463</td>\n",
       "      <td>47508</td>\n",
       "      <td>10424</td>\n",
       "      <td>20666</td>\n",
       "      <td>139156</td>\n",
       "      <td>124261</td>\n",
       "      <td>43394</td>\n",
       "      <td>89583</td>\n",
       "      <td>56574</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6.9</td>\n",
       "      <td>5.8</td>\n",
       "      <td>Alaska</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "0 STATE_ABB FIPS  CD Median household income Median nonfamily income  \\\n",
       "1        AK   02  01                   75463                   47508   \n",
       "\n",
       "0 Less than 9th grade 9th to 12th grade, no diploma  \\\n",
       "1               10424                         20666   \n",
       "\n",
       "0 High school graduate (includes equivalency) Some college, no degree  \\\n",
       "1                                      139156                  124261   \n",
       "\n",
       "0 Associates degree Bachelors degree Graduate or professional degree  \\\n",
       "1             43394            89583                           56574   \n",
       "\n",
       "0 Persons aged 18 to 64 in poverty Persons over 65 in poverty  \\\n",
       "1                              9.5                        6.9   \n",
       "\n",
       "0 Unemployed civilians   State  \n",
       "1                  5.8  Alaska  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One CD state for CD dataset\n",
    "my_dir = '/Users/darionguan/Desktop/Presidential Prediction/ACS/'\n",
    "filename = 'ACSprofileAlaska.csv'\n",
    "state_name = file_to_state(filename)\n",
    "# acs_df = read_one_cd(my_dir + filename, state_name)\n",
    "\n",
    "acs_df = pd.read_csv(my_dir + filename, header=None, usecols = [0, 1, 2, 3])\n",
    "\n",
    "# Omit first three rows\n",
    "acs_df = acs_df.iloc[3:,:]\n",
    "# Change this value to 'Stat'\n",
    "acs_df.iloc[1,0] = 'Stat'\n",
    "# Reset index\n",
    "acs_df = acs_df.reset_index(drop=True)\n",
    "\n",
    "# Transpose\n",
    "acs_df = acs_df.transpose()\n",
    "# Strip trailing whitespace\n",
    "acs_df.iloc[0] = acs_df.iloc[0].str.strip()\n",
    "# First row becomes column names\n",
    "acs_df.columns = acs_df.iloc[0]\n",
    "# Drop first row\n",
    "acs_df = acs_df.drop([0])\n",
    "# Forward fill NaN on 'Subject' column\n",
    "acs_df.loc[:,['Subject']] = acs_df.loc[:,['Subject']].ffill()\n",
    "# If one CD, then change 'Subject' to '1'\n",
    "acs_df.loc[acs_df['Subject'].str.startswith('Congressional District (at'), 'Subject'] = '1'.zfill(2)\n",
    "# For DC, 'Subject' string starts with 'Delegate' as opposed to 'Congressional...'\n",
    "acs_df.loc[acs_df['Subject'].str.startswith('Delegate'), 'Subject'] = '1'.zfill(2)\n",
    "# Rename 'Subject' column to 'CD'\n",
    "acs_df = acs_df.rename(columns={'Subject': 'CD'})\n",
    "\n",
    "# Subset where Stat column is 'Pct'\n",
    "pct_df = acs_df[acs_df['Stat'] == 'Pct']\n",
    "\n",
    "# Subset where Stat column is 'Number'\n",
    "acs_df = acs_df[acs_df['Stat'] == 'Number']\n",
    "\n",
    "# Drop 'Stat' column\n",
    "acs_df.drop('Stat', axis=1, inplace=True)\n",
    "pct_df.drop('Stat', axis=1, inplace=True)\n",
    "\n",
    "# Subset percentages\n",
    "pct_df = pct_df[['CD', 'Persons aged 18 to 64 in poverty', 'Persons over 65 in poverty', 'Unemployed civilians']]\n",
    "\n",
    "# Subset main df\n",
    "acs_df = acs_df[['CD', 'Median household income', 'Median nonfamily income', 'Less than 9th grade',\n",
    "                 '9th to 12th grade, no diploma', 'High school graduate (includes equivalency)',\n",
    "                 'Some college, no degree', 'Associates degree', 'Bachelors degree',\n",
    "                 'Graduate or professional degree']]\n",
    "\n",
    "# Join columns from pct_df to acs_df\n",
    "acs_df['Persons aged 18 to 64 in poverty'] = pct_df['Persons aged 18 to 64 in poverty'].values\n",
    "acs_df['Persons over 65 in poverty'] = pct_df['Persons over 65 in poverty'].values\n",
    "acs_df['Unemployed civilians'] = pct_df['Unemployed civilians'].values\n",
    "\n",
    "# Set State column with default state name\n",
    "acs_df['State'] = state_name\n",
    "\n",
    "# Insert new column with state abbreviations based on state_abb_dict\n",
    "acs_df.insert(0, 'STATE_ABB', acs_df['State'].map(state_abb_dict))    \n",
    "# Insert column with FIPS state codes based on fips_dict\n",
    "acs_df.insert(1, 'FIPS', acs_df['State'].map(fips_dict))\n",
    "acs_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d61c0718",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATE_ABB</th>\n",
       "      <th>FIPS</th>\n",
       "      <th>CD</th>\n",
       "      <th>Median household income</th>\n",
       "      <th>Median nonfamily income</th>\n",
       "      <th>Less than 9th grade</th>\n",
       "      <th>9th to 12th grade, no diploma</th>\n",
       "      <th>High school graduate (includes equivalency)</th>\n",
       "      <th>Some college, no degree</th>\n",
       "      <th>Associates degree</th>\n",
       "      <th>Bachelors degree</th>\n",
       "      <th>Graduate or professional degree</th>\n",
       "      <th>Persons aged 18 to 64 in poverty</th>\n",
       "      <th>Persons over 65 in poverty</th>\n",
       "      <th>Unemployed civilians</th>\n",
       "      <th>State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AL</td>\n",
       "      <td>01</td>\n",
       "      <td>01</td>\n",
       "      <td>50663</td>\n",
       "      <td>30805</td>\n",
       "      <td>14362</td>\n",
       "      <td>44540</td>\n",
       "      <td>167287</td>\n",
       "      <td>103009</td>\n",
       "      <td>44489</td>\n",
       "      <td>80114</td>\n",
       "      <td>44217</td>\n",
       "      <td>14.4</td>\n",
       "      <td>10.2</td>\n",
       "      <td>5.7</td>\n",
       "      <td>Alabama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AL</td>\n",
       "      <td>01</td>\n",
       "      <td>02</td>\n",
       "      <td>50494</td>\n",
       "      <td>31799</td>\n",
       "      <td>19065</td>\n",
       "      <td>42762</td>\n",
       "      <td>147536</td>\n",
       "      <td>100874</td>\n",
       "      <td>43236</td>\n",
       "      <td>68419</td>\n",
       "      <td>40177</td>\n",
       "      <td>15.6</td>\n",
       "      <td>8.8</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Alabama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AL</td>\n",
       "      <td>01</td>\n",
       "      <td>03</td>\n",
       "      <td>51925</td>\n",
       "      <td>25093</td>\n",
       "      <td>23068</td>\n",
       "      <td>49441</td>\n",
       "      <td>150179</td>\n",
       "      <td>99658</td>\n",
       "      <td>47236</td>\n",
       "      <td>65939</td>\n",
       "      <td>50452</td>\n",
       "      <td>15.4</td>\n",
       "      <td>10.2</td>\n",
       "      <td>5.9</td>\n",
       "      <td>Alabama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AL</td>\n",
       "      <td>01</td>\n",
       "      <td>04</td>\n",
       "      <td>47531</td>\n",
       "      <td>22794</td>\n",
       "      <td>24930</td>\n",
       "      <td>56731</td>\n",
       "      <td>163910</td>\n",
       "      <td>105245</td>\n",
       "      <td>43963</td>\n",
       "      <td>54939</td>\n",
       "      <td>29016</td>\n",
       "      <td>14.7</td>\n",
       "      <td>11.2</td>\n",
       "      <td>4.3</td>\n",
       "      <td>Alabama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AL</td>\n",
       "      <td>01</td>\n",
       "      <td>05</td>\n",
       "      <td>59950</td>\n",
       "      <td>33709</td>\n",
       "      <td>17397</td>\n",
       "      <td>36831</td>\n",
       "      <td>138163</td>\n",
       "      <td>101670</td>\n",
       "      <td>44494</td>\n",
       "      <td>106173</td>\n",
       "      <td>64018</td>\n",
       "      <td>12.8</td>\n",
       "      <td>7.9</td>\n",
       "      <td>4.3</td>\n",
       "      <td>Alabama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AL</td>\n",
       "      <td>01</td>\n",
       "      <td>06</td>\n",
       "      <td>69072</td>\n",
       "      <td>36650</td>\n",
       "      <td>14533</td>\n",
       "      <td>29426</td>\n",
       "      <td>114939</td>\n",
       "      <td>101328</td>\n",
       "      <td>38726</td>\n",
       "      <td>115867</td>\n",
       "      <td>70983</td>\n",
       "      <td>8.6</td>\n",
       "      <td>9.2</td>\n",
       "      <td>3.3</td>\n",
       "      <td>Alabama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AL</td>\n",
       "      <td>01</td>\n",
       "      <td>07</td>\n",
       "      <td>38023</td>\n",
       "      <td>24132</td>\n",
       "      <td>16965</td>\n",
       "      <td>43022</td>\n",
       "      <td>157227</td>\n",
       "      <td>88689</td>\n",
       "      <td>39770</td>\n",
       "      <td>56524</td>\n",
       "      <td>38519</td>\n",
       "      <td>22</td>\n",
       "      <td>16.7</td>\n",
       "      <td>6.8</td>\n",
       "      <td>Alabama</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "0 STATE_ABB FIPS  CD Median household income Median nonfamily income  \\\n",
       "0        AL   01  01                   50663                   30805   \n",
       "1        AL   01  02                   50494                   31799   \n",
       "2        AL   01  03                   51925                   25093   \n",
       "3        AL   01  04                   47531                   22794   \n",
       "4        AL   01  05                   59950                   33709   \n",
       "5        AL   01  06                   69072                   36650   \n",
       "6        AL   01  07                   38023                   24132   \n",
       "\n",
       "0 Less than 9th grade 9th to 12th grade, no diploma  \\\n",
       "0               14362                         44540   \n",
       "1               19065                         42762   \n",
       "2               23068                         49441   \n",
       "3               24930                         56731   \n",
       "4               17397                         36831   \n",
       "5               14533                         29426   \n",
       "6               16965                         43022   \n",
       "\n",
       "0 High school graduate (includes equivalency) Some college, no degree  \\\n",
       "0                                      167287                  103009   \n",
       "1                                      147536                  100874   \n",
       "2                                      150179                   99658   \n",
       "3                                      163910                  105245   \n",
       "4                                      138163                  101670   \n",
       "5                                      114939                  101328   \n",
       "6                                      157227                   88689   \n",
       "\n",
       "0 Associates degree Bachelors degree Graduate or professional degree  \\\n",
       "0             44489            80114                           44217   \n",
       "1             43236            68419                           40177   \n",
       "2             47236            65939                           50452   \n",
       "3             43963            54939                           29016   \n",
       "4             44494           106173                           64018   \n",
       "5             38726           115867                           70983   \n",
       "6             39770            56524                           38519   \n",
       "\n",
       "0 Persons aged 18 to 64 in poverty Persons over 65 in poverty  \\\n",
       "0                             14.4                       10.2   \n",
       "1                             15.6                        8.8   \n",
       "2                             15.4                       10.2   \n",
       "3                             14.7                       11.2   \n",
       "4                             12.8                        7.9   \n",
       "5                              8.6                        9.2   \n",
       "6                               22                       16.7   \n",
       "\n",
       "0 Unemployed civilians    State  \n",
       "0                  5.7  Alabama  \n",
       "1                  4.5  Alabama  \n",
       "2                  5.9  Alabama  \n",
       "3                  4.3  Alabama  \n",
       "4                  4.3  Alabama  \n",
       "5                  3.3  Alabama  \n",
       "6                  6.8  Alabama  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multi- CD state for CD dataset\n",
    "\n",
    "my_dir = '/Users/darionguan/Desktop/Presidential Prediction/ACS/'\n",
    "filename = 'ACSprofileAlabama.csv'\n",
    "state_name = file_to_state(filename)\n",
    "cols = new_arr(state_dict[file_to_state(filename)])\n",
    "state_name = file_to_state(filename)\n",
    "# acs_df = read_multi_cd(my_dir + filename, state_name)\n",
    "\n",
    "acs_df = pd.read_csv(my_dir + filename, header=None, usecols=cols)\n",
    "\n",
    "# Omit first three rows\n",
    "acs_df = acs_df.iloc[3:,:]\n",
    "# Change this value to 'Stat'\n",
    "acs_df.iloc[1,0] = 'Stat'\n",
    "# Reset index\n",
    "acs_df = acs_df.reset_index(drop=True)\n",
    "\n",
    "# Transpose\n",
    "acs_df = acs_df.transpose()\n",
    "# Strip trailing whitespace\n",
    "acs_df.iloc[0] = acs_df.iloc[0].str.strip()\n",
    "# First row becomes column names\n",
    "acs_df.columns = acs_df.iloc[0]\n",
    "# Drop first row\n",
    "acs_df = acs_df.drop([0])\n",
    "# Forward fill NaN on 'Subject' column\n",
    "acs_df.loc[:,['Subject']] = acs_df.loc[:,['Subject']].ffill()\n",
    "# Substring 'Subject' values\n",
    "acs_df['Subject'] = acs_df.Subject.mask(acs_df.Subject.str.len() > 24, acs_df.Subject.str[0:25])\n",
    "# Strip trailing whitespace\n",
    "acs_df['Subject'] = acs_df['Subject'].str.rstrip()\n",
    "# Substring to last two characters if 'Subject' values start with 'Congressional'\n",
    "acs_df['Subject'] = acs_df.Subject.mask(acs_df.Subject.str.startswith('Congressional'), acs_df.Subject.str[-2:])\n",
    "# Strip leading whitespace\n",
    "acs_df['Subject'] = acs_df['Subject'].str.lstrip()\n",
    "# Fill in leading zeros\n",
    "acs_df['Subject'] = acs_df['Subject'].astype(str).str.zfill(2)\n",
    "\n",
    "# Rename 'Subject' column to 'CD'\n",
    "acs_df = acs_df.rename(columns={'Subject': 'CD'})\n",
    "\n",
    "# Subset where Stat column is 'Pct'\n",
    "pct_df = acs_df[acs_df['Stat'] == 'Pct']\n",
    "\n",
    "# Subset where Stat column is 'Number'\n",
    "acs_df = acs_df[acs_df['Stat'] == 'Number']\n",
    "\n",
    "# Drop 'Stat' column\n",
    "acs_df.drop('Stat', axis=1, inplace=True)\n",
    "pct_df.drop('Stat', axis=1, inplace=True)\n",
    "\n",
    "# Subset percentages\n",
    "pct_df = pct_df[['CD', 'Persons aged 18 to 64 in poverty', 'Persons over 65 in poverty', 'Unemployed civilians']]\n",
    "\n",
    "# Subset main df\n",
    "acs_df = acs_df[['CD', 'Median household income', 'Median nonfamily income', 'Less than 9th grade',\n",
    "                 '9th to 12th grade, no diploma', 'High school graduate (includes equivalency)',\n",
    "                 'Some college, no degree', 'Associates degree', 'Bachelors degree',\n",
    "                 'Graduate or professional degree']]\n",
    "\n",
    "# Join columns from pct_df to acs_df\n",
    "acs_df['Persons aged 18 to 64 in poverty'] = pct_df['Persons aged 18 to 64 in poverty'].values\n",
    "acs_df['Persons over 65 in poverty'] = pct_df['Persons over 65 in poverty'].values\n",
    "acs_df['Unemployed civilians'] = pct_df['Unemployed civilians'].values\n",
    "\n",
    "# Set State column with default state name\n",
    "acs_df['State'] = state_name\n",
    "\n",
    "# Insert new column with state abbreviations based on state_abb_dict\n",
    "acs_df.insert(0, 'STATE_ABB', acs_df['State'].map(state_abb_dict))    \n",
    "# Insert column with FIPS state codes based on fips_dict\n",
    "acs_df.insert(1, 'FIPS', acs_df['State'].map(fips_dict))\n",
    "\n",
    "# Remove the last row\n",
    "acs_df = acs_df.iloc[:-1]\n",
    "# Reset index\n",
    "acs_df = acs_df.reset_index(drop=True)\n",
    "\n",
    "acs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79e96bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for reading in 1 CD state for CD dataset\n",
    "def read_one_cd(filename, state_name):\n",
    "    acs_df = pd.read_csv(filename, header=None, usecols=[0, 1, 2, 3])\n",
    "\n",
    "    # Omit first three rows\n",
    "    acs_df = acs_df.iloc[3:,:]\n",
    "    # Change this value to 'Stat'\n",
    "    acs_df.iloc[1,0] = 'Stat'\n",
    "    # Reset index\n",
    "    acs_df = acs_df.reset_index(drop=True)\n",
    "\n",
    "    # Transpose\n",
    "    acs_df = acs_df.transpose()\n",
    "    # Strip trailing whitespace\n",
    "    acs_df.iloc[0] = acs_df.iloc[0].str.strip()\n",
    "    # First row becomes column names\n",
    "    acs_df.columns = acs_df.iloc[0]\n",
    "    # Drop first row\n",
    "    acs_df = acs_df.drop([0])\n",
    "    # Forward fill NaN on 'Subject' column\n",
    "    acs_df.loc[:,['Subject']] = acs_df.loc[:,['Subject']].ffill()\n",
    "    # If one CD, then change 'Subject' to '1'\n",
    "    acs_df.loc[acs_df['Subject'].str.startswith('Congressional District (at'), 'Subject'] = '1'.zfill(2)\n",
    "    # For DC, 'Subject' string starts with 'Delegate' as opposed to 'Congressional...'\n",
    "    acs_df.loc[acs_df['Subject'].str.startswith('Delegate'), 'Subject'] = '1'.zfill(2)\n",
    "    # Fill in leading zeros\n",
    "    acs_df['Subject'] = acs_df['Subject'].astype(str).str.zfill(2)\n",
    "\n",
    "    # Rename 'Subject' column to 'CD'\n",
    "    acs_df = acs_df.rename(columns={'Subject': 'CD'})\n",
    "    \n",
    "    # Prep subset df\n",
    "    subset_df = acs_df[acs_df['Stat'] == 'Number']\n",
    "    subset_df = subset_df[['Median household income', 'Median nonfamily income']]\n",
    "    \n",
    "    # Prep main df\n",
    "    acs_df = acs_df[acs_df['Stat'] == 'Pct']\n",
    "    acs_df = acs_df[['CD', 'Persons aged 18 to 64 in poverty', 'Persons over 65 in poverty', 'Unemployed civilians',\n",
    "                     'Less than 9th grade', '9th to 12th grade, no diploma',\n",
    "                     'High school graduate (includes equivalency)', 'Some college, no degree',\n",
    "                     'Associates degree', 'Bachelors degree', 'Graduate or professional degree']]\n",
    "    \n",
    "    # Join columns from subset_df to acs_df\n",
    "    acs_df['Median household income'] = subset_df['Median household income'].values\n",
    "    acs_df['Median nonfamily income'] = subset_df['Median nonfamily income'].values\n",
    "\n",
    "    # Set State column with default state name\n",
    "    acs_df['State'] = state_name\n",
    "\n",
    "    # Insert new column with state abbreviations based on state_abb_dict\n",
    "    acs_df.insert(0, 'STATE_ABB', acs_df['State'].map(state_abb_dict))    \n",
    "    # Insert column with FIPS state codes based on fips_dict\n",
    "    acs_df.insert(1, 'FIPS', acs_df['State'].map(fips_dict))\n",
    "\n",
    "    # Reset index\n",
    "    acs_df = acs_df.reset_index(drop=True)\n",
    "\n",
    "    return acs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3dd1e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for reading multi-CD state for CD dataset\n",
    "def read_multi_cd(filename, cols, state_name):\n",
    "    acs_df = pd.read_csv(filename, header=None, usecols=cols)\n",
    "\n",
    "    # Omit first three rows\n",
    "    acs_df = acs_df.iloc[3:,:]\n",
    "    # Change this value to 'Stat'\n",
    "    acs_df.iloc[1,0] = 'Stat'\n",
    "    # Reset index\n",
    "    acs_df = acs_df.reset_index(drop=True)\n",
    "\n",
    "    # Transpose\n",
    "    acs_df = acs_df.transpose()\n",
    "    # Strip trailing whitespace\n",
    "    acs_df.iloc[0] = acs_df.iloc[0].str.strip()\n",
    "    # First row becomes column names\n",
    "    acs_df.columns = acs_df.iloc[0]\n",
    "    # Drop first row\n",
    "    acs_df = acs_df.drop([0])\n",
    "    # Forward fill NaN on 'Subject' column\n",
    "    acs_df.loc[:,['Subject']] = acs_df.loc[:,['Subject']].ffill()\n",
    "    # Substring 'Subject' values\n",
    "    acs_df['Subject'] = acs_df.Subject.mask(acs_df.Subject.str.len() > 24, acs_df.Subject.str[0:25])\n",
    "    # Strip trailing whitespace\n",
    "    acs_df['Subject'] = acs_df['Subject'].str.rstrip()\n",
    "    # Substring to last two characters if 'Subject' values start with 'Congressional'\n",
    "    acs_df['Subject'] = acs_df.Subject.mask(acs_df.Subject.str.startswith('Congressional'), acs_df.Subject.str[-2:])\n",
    "    # Strip leading whitespace\n",
    "    acs_df['Subject'] = acs_df['Subject'].str.lstrip()\n",
    "    # Fill in leading zeros\n",
    "    acs_df['Subject'] = acs_df['Subject'].astype(str).str.zfill(2)\n",
    "\n",
    "    # Rename 'Subject' column to 'CD'\n",
    "    acs_df = acs_df.rename(columns={'Subject': 'CD'})\n",
    "\n",
    "    # Prep subset df\n",
    "    subset_df = acs_df[acs_df['Stat'] == 'Number']\n",
    "    subset_df = subset_df[['Median household income', 'Median nonfamily income']]\n",
    "    \n",
    "    # Prep main df\n",
    "    acs_df = acs_df[acs_df['Stat'] == 'Pct']\n",
    "    acs_df = acs_df[['CD', 'Persons aged 18 to 64 in poverty', 'Persons over 65 in poverty', 'Unemployed civilians',\n",
    "                     'Less than 9th grade', '9th to 12th grade, no diploma',\n",
    "                     'High school graduate (includes equivalency)', 'Some college, no degree',\n",
    "                     'Associates degree', 'Bachelors degree', 'Graduate or professional degree']]\n",
    "    \n",
    "    # Join columns from subset_df to acs_df\n",
    "    acs_df['Median household income'] = subset_df['Median household income'].values\n",
    "    acs_df['Median nonfamily income'] = subset_df['Median nonfamily income'].values\n",
    "\n",
    "    # Set State column with default state name\n",
    "    acs_df['State'] = state_name\n",
    "\n",
    "    # Insert new column with state abbreviations based on state_abb_dict\n",
    "    acs_df.insert(0, 'STATE_ABB', acs_df['State'].map(state_abb_dict))    \n",
    "    # Insert column with FIPS state codes based on fips_dict\n",
    "    acs_df.insert(1, 'FIPS', acs_df['State'].map(fips_dict))\n",
    "\n",
    "    # Remove the last row\n",
    "    acs_df = acs_df.iloc[:-1]\n",
    "    # Reset index\n",
    "    acs_df = acs_df.reset_index(drop=True)\n",
    "\n",
    "    return acs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74740b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loop_cds():\n",
    "    # Make an empty dataframe\n",
    "    acs_final_df = create_df()\n",
    "    \n",
    "    # Directory path\n",
    "    my_dir = '/Users/darionguan/Desktop/Presidential Prediction/ACS/'\n",
    "\n",
    "    # For every file in lst\n",
    "    for filename in os.listdir(my_dir):\n",
    "        # If the file ends with name of state that has 1 CD\n",
    "        # Last statement used to dodge .DS_Store file\n",
    "        if (filename.endswith('Alaska.csv') or filename.endswith('Delaware.csv') or filename.endswith('DC.csv') \\\n",
    "        or filename.endswith('Montana.csv') or filename.endswith('NorthDakota.csv') \\\n",
    "        or filename.endswith('SouthDakota.csv') or filename.endswith('Vermont.csv') \\\n",
    "        or filename.endswith('Wyoming.csv')) and filename.startswith('.') is False:\n",
    "            # state_name variable to be used in read_one_cd() function\n",
    "            state_name = file_to_state(filename)\n",
    "            # Use function for reading 1 CD state\n",
    "            acs_df = read_one_cd(my_dir + filename, state_name)\n",
    "            # Concatenate working acs_df to acs_final_df\n",
    "            acs_final_df = pd.concat([acs_final_df, acs_df], ignore_index=True)\n",
    "\n",
    "        # Else - statement used to dodge .DS_Store file\n",
    "        elif filename.startswith('.') is False:\n",
    "            # Use file_to_state() to find state name from filename\n",
    "            # Use state name as key to find corresponding number of CDs in state_dict\n",
    "            # Create an array to be used as number of cols read from csv\n",
    "            cols = new_arr(state_dict[file_to_state(filename)])\n",
    "            # state_name variable to be used in read_multi_cd() function\n",
    "            state_name = file_to_state(filename)\n",
    "            # Use function for reading multi-CD state\n",
    "            acs_df = read_multi_cd(my_dir + filename, cols, state_name)\n",
    "            # Concatenate working acs_df to acs_final_df\n",
    "            acs_final_df = pd.concat([acs_final_df, acs_df], ignore_index=True)\n",
    "            \n",
    "    return acs_final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7cf39727",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>STATE_ABB</th>\n",
       "      <th>FIPS</th>\n",
       "      <th>CD</th>\n",
       "      <th>MedianHouseholdIncome</th>\n",
       "      <th>MedianNonfamilyIncome</th>\n",
       "      <th>Pct18to64InPoverty</th>\n",
       "      <th>PctOver65InPoverty</th>\n",
       "      <th>PctUnemployedCivilians</th>\n",
       "      <th>PctLessThan9thGrade</th>\n",
       "      <th>Pct9thto12thGrade</th>\n",
       "      <th>PctHSGrad</th>\n",
       "      <th>PctSomeCollege</th>\n",
       "      <th>PctAssociatesDeg</th>\n",
       "      <th>PctBachelorsDeg</th>\n",
       "      <th>PctGradDeg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>AL</td>\n",
       "      <td>01</td>\n",
       "      <td>01</td>\n",
       "      <td>50663</td>\n",
       "      <td>30805</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.336</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>AL</td>\n",
       "      <td>01</td>\n",
       "      <td>02</td>\n",
       "      <td>50494</td>\n",
       "      <td>31799</td>\n",
       "      <td>0.156</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.319</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>AL</td>\n",
       "      <td>01</td>\n",
       "      <td>03</td>\n",
       "      <td>51925</td>\n",
       "      <td>25093</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.309</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.136</td>\n",
       "      <td>0.104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>AL</td>\n",
       "      <td>01</td>\n",
       "      <td>04</td>\n",
       "      <td>47531</td>\n",
       "      <td>22794</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>AL</td>\n",
       "      <td>01</td>\n",
       "      <td>05</td>\n",
       "      <td>59950</td>\n",
       "      <td>33709</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.272</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.209</td>\n",
       "      <td>0.126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>WI</td>\n",
       "      <td>55</td>\n",
       "      <td>05</td>\n",
       "      <td>77386</td>\n",
       "      <td>44574</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.263</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>WI</td>\n",
       "      <td>55</td>\n",
       "      <td>06</td>\n",
       "      <td>63251</td>\n",
       "      <td>40066</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.337</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.113</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>WI</td>\n",
       "      <td>55</td>\n",
       "      <td>07</td>\n",
       "      <td>60706</td>\n",
       "      <td>33054</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.345</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>WI</td>\n",
       "      <td>55</td>\n",
       "      <td>08</td>\n",
       "      <td>65346</td>\n",
       "      <td>38058</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.335</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>WY</td>\n",
       "      <td>56</td>\n",
       "      <td>01</td>\n",
       "      <td>65003</td>\n",
       "      <td>37299</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.301</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.113</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>437 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         State STATE_ABB FIPS  CD  MedianHouseholdIncome  \\\n",
       "0      Alabama        AL   01  01                  50663   \n",
       "1      Alabama        AL   01  02                  50494   \n",
       "2      Alabama        AL   01  03                  51925   \n",
       "3      Alabama        AL   01  04                  47531   \n",
       "4      Alabama        AL   01  05                  59950   \n",
       "..         ...       ...  ...  ..                    ...   \n",
       "432  Wisconsin        WI   55  05                  77386   \n",
       "433  Wisconsin        WI   55  06                  63251   \n",
       "434  Wisconsin        WI   55  07                  60706   \n",
       "435  Wisconsin        WI   55  08                  65346   \n",
       "436    Wyoming        WY   56  01                  65003   \n",
       "\n",
       "     MedianNonfamilyIncome  Pct18to64InPoverty  PctOver65InPoverty  \\\n",
       "0                    30805               0.144               0.102   \n",
       "1                    31799               0.156               0.088   \n",
       "2                    25093               0.154               0.102   \n",
       "3                    22794               0.147               0.112   \n",
       "4                    33709               0.128               0.079   \n",
       "..                     ...                 ...                 ...   \n",
       "432                  44574               0.060               0.070   \n",
       "433                  40066               0.070               0.079   \n",
       "434                  33054               0.092               0.076   \n",
       "435                  38058               0.081               0.068   \n",
       "436                  37299               0.103               0.074   \n",
       "\n",
       "     PctUnemployedCivilians  PctLessThan9thGrade  Pct9thto12thGrade  \\\n",
       "0                     0.057                0.029              0.089   \n",
       "1                     0.045                0.041              0.093   \n",
       "2                     0.059                0.047              0.102   \n",
       "3                     0.043                0.052              0.119   \n",
       "4                     0.043                0.034              0.072   \n",
       "..                      ...                  ...                ...   \n",
       "432                   0.032                0.018              0.033   \n",
       "433                   0.025                0.019              0.049   \n",
       "434                   0.029                0.023              0.052   \n",
       "435                   0.029                0.027              0.043   \n",
       "436                   0.036                0.017              0.038   \n",
       "\n",
       "     PctHSGrad  PctSomeCollege  PctAssociatesDeg  PctBachelorsDeg  PctGradDeg  \n",
       "0        0.336           0.207             0.089            0.161       0.089  \n",
       "1        0.319           0.218             0.094            0.148       0.087  \n",
       "2        0.309           0.205             0.097            0.136       0.104  \n",
       "3        0.342           0.220             0.092            0.115       0.061  \n",
       "4        0.272           0.200             0.087            0.209       0.126  \n",
       "..         ...             ...               ...              ...         ...  \n",
       "432      0.263           0.200             0.105            0.260       0.123  \n",
       "433      0.337           0.199             0.113            0.194       0.088  \n",
       "434      0.345           0.210             0.126            0.167       0.077  \n",
       "435      0.335           0.202             0.120            0.191       0.081  \n",
       "436      0.301           0.240             0.113            0.188       0.104  \n",
       "\n",
       "[437 rows x 16 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acs_final_df = loop_cds()\n",
    "    \n",
    "# Sort by the below columns\n",
    "acs_final_df = acs_final_df.sort_values(by=['FIPS', 'CD'], ascending=[True, True])\n",
    "\n",
    "# Reindex\n",
    "acs_final_df = acs_final_df.reset_index(drop=True)\n",
    "\n",
    "# Convert dtypes\n",
    "acs_final_df = acs_final_df.astype({'Median household income': 'int64',\n",
    "                                    'Median nonfamily income': 'int64',\n",
    "                                    'Persons aged 18 to 64 in poverty': 'float64',\n",
    "                                    'Persons over 65 in poverty': 'float64',\n",
    "                                    'Unemployed civilians': 'float64',\n",
    "                                    'Less than 9th grade': 'float64',\n",
    "                                    '9th to 12th grade, no diploma': 'float64',\n",
    "                                    'High school graduate (includes equivalency)': 'float64',\n",
    "                                    'Some college, no degree': 'float64',\n",
    "                                    'Associates degree': 'float64',\n",
    "                                    'Bachelors degree': 'float64',\n",
    "                                    'Graduate or professional degree': 'float64'})\n",
    "\n",
    "# Rename columns\n",
    "acs_final_df = acs_final_df.rename(columns={acs_final_df.columns[4]: 'MedianHouseholdIncome',\n",
    "                                            acs_final_df.columns[5]: 'MedianNonfamilyIncome',\n",
    "                                            acs_final_df.columns[6]: 'Pct18to64InPoverty',\n",
    "                                            acs_final_df.columns[7]: 'PctOver65InPoverty',\n",
    "                                            acs_final_df.columns[8]: 'PctUnemployedCivilians',\n",
    "                                            acs_final_df.columns[9]: 'PctLessThan9thGrade',\n",
    "                                            acs_final_df.columns[10]: 'Pct9thto12thGrade',\n",
    "                                            acs_final_df.columns[11]: 'PctHSGrad',\n",
    "                                            acs_final_df.columns[12]: 'PctSomeCollege',\n",
    "                                            acs_final_df.columns[13]: 'PctAssociatesDeg',\n",
    "                                            acs_final_df.columns[14]: 'PctBachelorsDeg',\n",
    "                                            acs_final_df.columns[15]: 'PctGradDeg'})\n",
    "\n",
    "# Convert percentages to decimal\n",
    "acs_final_df['Pct18to64InPoverty'] = acs_final_df['Pct18to64InPoverty'] / 100\n",
    "acs_final_df['PctOver65InPoverty'] = acs_final_df['PctOver65InPoverty'] / 100\n",
    "acs_final_df['PctUnemployedCivilians'] = acs_final_df['PctUnemployedCivilians'] / 100\n",
    "acs_final_df['PctLessThan9thGrade'] = acs_final_df['PctLessThan9thGrade'] / 100\n",
    "acs_final_df['Pct9thto12thGrade'] = acs_final_df['Pct9thto12thGrade'] / 100\n",
    "acs_final_df['PctHSGrad'] = acs_final_df['PctHSGrad'] / 100\n",
    "acs_final_df['PctSomeCollege'] = acs_final_df['PctSomeCollege'] / 100\n",
    "acs_final_df['PctAssociatesDeg'] = acs_final_df['PctAssociatesDeg'] / 100\n",
    "acs_final_df['PctBachelorsDeg'] = acs_final_df['PctBachelorsDeg'] / 100\n",
    "acs_final_df['PctGradDeg'] = acs_final_df['PctGradDeg'] / 100\n",
    "\n",
    "# Convert df to csv\n",
    "acs_final_df.to_csv('acs_cd_final.csv')\n",
    "\n",
    "acs_final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24c9cb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for reading in 1 CD state for CD dataset\n",
    "def read_one_state(filename, state_name):\n",
    "    acs_df = pd.read_csv(filename, header=None, usecols=[0, 1, 2, 3])\n",
    "\n",
    "    # Omit first three rows\n",
    "    acs_df = acs_df.iloc[3:,:]\n",
    "    # Change this value to 'Stat'\n",
    "    acs_df.iloc[1,0] = 'Stat'\n",
    "    # Reset index\n",
    "    acs_df = acs_df.reset_index(drop=True)\n",
    "\n",
    "    # Transpose\n",
    "    acs_df = acs_df.transpose()\n",
    "    # Strip trailing whitespace\n",
    "    acs_df.iloc[0] = acs_df.iloc[0].str.strip()\n",
    "    # First row becomes column names\n",
    "    acs_df.columns = acs_df.iloc[0]\n",
    "    # Drop first row\n",
    "    acs_df = acs_df.drop([0])\n",
    "    # Forward fill NaN on 'Subject' column\n",
    "    acs_df.loc[:,['Subject']] = acs_df.loc[:,['Subject']].ffill()\n",
    "    \n",
    "#     # If one CD, then change 'Subject' to '1'\n",
    "#     acs_df.loc[acs_df['Subject'].str.startswith('Congressional District (at'), 'Subject'] = '1'.zfill(2)\n",
    "#     # For DC, 'Subject' string starts with 'Delegate' as opposed to 'Congressional...'\n",
    "#     acs_df.loc[acs_df['Subject'].str.startswith('Delegate'), 'Subject'] = '1'.zfill(2)\n",
    "#     # Fill in leading zeros\n",
    "#     acs_df['Subject'] = acs_df['Subject'].astype(str).str.zfill(2)\n",
    "\n",
    "    # Change all rows of 'Subject' column to state_name\n",
    "    acs_df['Subject'] = state_name\n",
    "\n",
    "    # Rename 'Subject' column to 'State'\n",
    "    acs_df = acs_df.rename(columns={'Subject': 'State'})\n",
    "    \n",
    "    # Prep subset df\n",
    "    subset_df = acs_df[acs_df['Stat'] == 'Number']\n",
    "    subset_df = subset_df[['Median household income', 'Median nonfamily income']]\n",
    "    \n",
    "    # Prep main df\n",
    "    acs_df = acs_df[acs_df['Stat'] == 'Pct']\n",
    "    acs_df = acs_df[['State', 'Persons aged 18 to 64 in poverty', 'Persons over 65 in poverty', 'Unemployed civilians',\n",
    "                     'Less than 9th grade', '9th to 12th grade, no diploma',\n",
    "                     'High school graduate (includes equivalency)', 'Some college, no degree',\n",
    "                     'Associates degree', 'Bachelors degree', 'Graduate or professional degree']]\n",
    "    \n",
    "    # Join columns from subset_df to acs_df\n",
    "    acs_df['Median household income'] = subset_df['Median household income'].values\n",
    "    acs_df['Median nonfamily income'] = subset_df['Median nonfamily income'].values\n",
    "\n",
    "    # Insert new column with state abbreviations based on state_abb_dict\n",
    "    acs_df.insert(0, 'STATE_ABB', acs_df['State'].map(state_abb_dict))    \n",
    "    # Insert column with FIPS state codes based on fips_dict\n",
    "    acs_df.insert(1, 'FIPS', acs_df['State'].map(fips_dict))\n",
    "\n",
    "    # Reset index\n",
    "    acs_df = acs_df.reset_index(drop=True)\n",
    "\n",
    "    return acs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce4dcb9c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Function for reading multi-CD state for state dataset\n",
    "def read_multi_state(filename, cols, state_name):\n",
    "    acs_df = pd.read_csv(filename, header=None, usecols=cols)\n",
    "\n",
    "    # Omit first three rows\n",
    "    acs_df = acs_df.iloc[3:,:]\n",
    "    # Change this value to 'Stat'\n",
    "    acs_df.iloc[1,0] = 'Stat'\n",
    "    # Reset index\n",
    "    acs_df = acs_df.reset_index(drop=True)\n",
    "\n",
    "    # Transpose\n",
    "    acs_df = acs_df.transpose()\n",
    "    # Strip trailing whitespace\n",
    "    acs_df.iloc[0] = acs_df.iloc[0].str.strip()\n",
    "    # First row becomes column names\n",
    "    acs_df.columns = acs_df.iloc[0]\n",
    "    # Drop first row\n",
    "    acs_df = acs_df.drop([0])\n",
    "    # Forward fill NaN on 'Subject' column\n",
    "    acs_df.loc[:,['Subject']] = acs_df.loc[:,['Subject']].ffill()\n",
    "    \n",
    "    # Keep last three rows\n",
    "    acs_df = acs_df[-3:]\n",
    "\n",
    "    # Change all rows of 'Subject' column to state_name\n",
    "    acs_df['Subject'] = state_name\n",
    "\n",
    "    # Rename 'Subject' column to 'State'\n",
    "    acs_df = acs_df.rename(columns={'Subject': 'State'})\n",
    "\n",
    "    # Prep subset df\n",
    "    subset_df = acs_df[acs_df['Stat'] == 'Number']\n",
    "    subset_df = subset_df[['Median household income', 'Median nonfamily income']]\n",
    "    \n",
    "    # Prep main df\n",
    "    acs_df = acs_df[acs_df['Stat'] == 'Pct']\n",
    "    acs_df = acs_df[['State', 'Persons aged 18 to 64 in poverty', 'Persons over 65 in poverty', 'Unemployed civilians',\n",
    "                     'Less than 9th grade', '9th to 12th grade, no diploma',\n",
    "                     'High school graduate (includes equivalency)', 'Some college, no degree',\n",
    "                     'Associates degree', 'Bachelors degree', 'Graduate or professional degree']]\n",
    "    \n",
    "    # Join columns from subset_df to acs_df\n",
    "    acs_df['Median household income'] = subset_df['Median household income'].values\n",
    "    acs_df['Median nonfamily income'] = subset_df['Median nonfamily income'].values\n",
    "\n",
    "    # Insert new column with state abbreviations based on state_abb_dict\n",
    "    acs_df.insert(0, 'STATE_ABB', acs_df['State'].map(state_abb_dict))    \n",
    "    # Insert column with FIPS state codes based on fips_dict\n",
    "    acs_df.insert(1, 'FIPS', acs_df['State'].map(fips_dict))\n",
    "\n",
    "    # Reset index\n",
    "    acs_df = acs_df.reset_index(drop=True)\n",
    "\n",
    "    return acs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0dee234f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loop_states():\n",
    "    # Make an empty dataframe\n",
    "    acs_final_df = create_df()\n",
    "    \n",
    "    # Directory path\n",
    "    my_dir = '/Users/darionguan/Desktop/Presidential Prediction/ACS/'\n",
    "    \n",
    "    # For every file in lst\n",
    "    for filename in os.listdir(my_dir):\n",
    "        # If the file ends with name of state that has 1 CD\n",
    "        # Last statement used to dodge .DS_Store file\n",
    "        if (filename.endswith('Alaska.csv') or filename.endswith('Delaware.csv') or filename.endswith('DC.csv') \\\n",
    "        or filename.endswith('Montana.csv') or filename.endswith('NorthDakota.csv') \\\n",
    "        or filename.endswith('SouthDakota.csv') or filename.endswith('Vermont.csv') \\\n",
    "        or filename.endswith('Wyoming.csv')) and filename.startswith('.') is False:\n",
    "            # state_name variable to be used in read_one_cd() function\n",
    "            state_name = file_to_state(filename)\n",
    "            # Use function for reading 1 CD state\n",
    "            acs_df = read_one_state(my_dir + filename, state_name)\n",
    "            # Concatenate working acs_df to acs_final_df\n",
    "            acs_final_df = pd.concat([acs_final_df, acs_df], ignore_index=True)\n",
    "\n",
    "        # Else - statement used to dodge .DS_Store file\n",
    "        elif filename.startswith('.') is False:\n",
    "            # Use file_to_state() to find state name from filename\n",
    "            # Use state name as key to find corresponding number of CDs in state_dict\n",
    "            # Create an array to be used as number of cols read from csv\n",
    "            cols = new_arr(state_dict[file_to_state(filename)])\n",
    "            # state_name variable to be used in read_multi_cd() function\n",
    "            state_name = file_to_state(filename)\n",
    "            # Use function for reading multi-CD state\n",
    "            acs_df = read_multi_state(my_dir + filename, cols, state_name)\n",
    "            # Concatenate working acs_df to acs_final_df\n",
    "            acs_final_df = pd.concat([acs_final_df, acs_df], ignore_index=True)\n",
    "    return acs_final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8959c1ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>STATE_ABB</th>\n",
       "      <th>FIPS</th>\n",
       "      <th>MedianHouseholdIncome</th>\n",
       "      <th>MedianNonfamilyIncome</th>\n",
       "      <th>Pct18to64InPoverty</th>\n",
       "      <th>PctOver65InPoverty</th>\n",
       "      <th>PctUnemployedCivilians</th>\n",
       "      <th>PctLessThan9thGrade</th>\n",
       "      <th>Pct9thto12thGrade</th>\n",
       "      <th>PctHSGrad</th>\n",
       "      <th>PctSomeCollege</th>\n",
       "      <th>PctAssociatesDeg</th>\n",
       "      <th>PctBachelorsDeg</th>\n",
       "      <th>PctGradDeg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>AL</td>\n",
       "      <td>01</td>\n",
       "      <td>51734</td>\n",
       "      <td>29458</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.309</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>AK</td>\n",
       "      <td>02</td>\n",
       "      <td>75463</td>\n",
       "      <td>47508</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.287</td>\n",
       "      <td>0.257</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>AZ</td>\n",
       "      <td>04</td>\n",
       "      <td>62055</td>\n",
       "      <td>40198</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.237</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>AR</td>\n",
       "      <td>05</td>\n",
       "      <td>48952</td>\n",
       "      <td>27607</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>CA</td>\n",
       "      <td>06</td>\n",
       "      <td>80440</td>\n",
       "      <td>51676</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Colorado</td>\n",
       "      <td>CO</td>\n",
       "      <td>08</td>\n",
       "      <td>77127</td>\n",
       "      <td>50092</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.266</td>\n",
       "      <td>0.160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Connecticut</td>\n",
       "      <td>CT</td>\n",
       "      <td>09</td>\n",
       "      <td>78833</td>\n",
       "      <td>45001</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.268</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Delaware</td>\n",
       "      <td>DE</td>\n",
       "      <td>10</td>\n",
       "      <td>70176</td>\n",
       "      <td>44071</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.302</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DC</td>\n",
       "      <td>DC</td>\n",
       "      <td>11</td>\n",
       "      <td>92266</td>\n",
       "      <td>76529</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.257</td>\n",
       "      <td>0.340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Florida</td>\n",
       "      <td>FL</td>\n",
       "      <td>12</td>\n",
       "      <td>59227</td>\n",
       "      <td>37292</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.284</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Georgia</td>\n",
       "      <td>GA</td>\n",
       "      <td>13</td>\n",
       "      <td>61980</td>\n",
       "      <td>37881</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.274</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Hawaii</td>\n",
       "      <td>HI</td>\n",
       "      <td>15</td>\n",
       "      <td>83102</td>\n",
       "      <td>51343</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.274</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Idaho</td>\n",
       "      <td>ID</td>\n",
       "      <td>16</td>\n",
       "      <td>60999</td>\n",
       "      <td>35157</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.261</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Illinois</td>\n",
       "      <td>IL</td>\n",
       "      <td>17</td>\n",
       "      <td>69187</td>\n",
       "      <td>40860</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Indiana</td>\n",
       "      <td>IN</td>\n",
       "      <td>18</td>\n",
       "      <td>57603</td>\n",
       "      <td>33994</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.339</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Iowa</td>\n",
       "      <td>IA</td>\n",
       "      <td>19</td>\n",
       "      <td>61691</td>\n",
       "      <td>36559</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Kansas</td>\n",
       "      <td>KS</td>\n",
       "      <td>20</td>\n",
       "      <td>62087</td>\n",
       "      <td>36347</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.263</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.216</td>\n",
       "      <td>0.124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Kentucky</td>\n",
       "      <td>KY</td>\n",
       "      <td>21</td>\n",
       "      <td>52295</td>\n",
       "      <td>30384</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.332</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Louisiana</td>\n",
       "      <td>LA</td>\n",
       "      <td>22</td>\n",
       "      <td>51073</td>\n",
       "      <td>28907</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.339</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Maine</td>\n",
       "      <td>ME</td>\n",
       "      <td>23</td>\n",
       "      <td>58924</td>\n",
       "      <td>35624</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.314</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Maryland</td>\n",
       "      <td>MD</td>\n",
       "      <td>24</td>\n",
       "      <td>86738</td>\n",
       "      <td>51990</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.246</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>MA</td>\n",
       "      <td>25</td>\n",
       "      <td>85843</td>\n",
       "      <td>50338</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.239</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.247</td>\n",
       "      <td>0.203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Michigan</td>\n",
       "      <td>MI</td>\n",
       "      <td>26</td>\n",
       "      <td>59584</td>\n",
       "      <td>35755</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.291</td>\n",
       "      <td>0.228</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Minnesota</td>\n",
       "      <td>MN</td>\n",
       "      <td>27</td>\n",
       "      <td>74593</td>\n",
       "      <td>44136</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.245</td>\n",
       "      <td>0.127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Mississippi</td>\n",
       "      <td>MS</td>\n",
       "      <td>28</td>\n",
       "      <td>45792</td>\n",
       "      <td>25562</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.302</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Missouri</td>\n",
       "      <td>MO</td>\n",
       "      <td>29</td>\n",
       "      <td>57409</td>\n",
       "      <td>33821</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.214</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Montana</td>\n",
       "      <td>MT</td>\n",
       "      <td>30</td>\n",
       "      <td>57153</td>\n",
       "      <td>34919</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.284</td>\n",
       "      <td>0.229</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.231</td>\n",
       "      <td>0.105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Nebraska</td>\n",
       "      <td>NE</td>\n",
       "      <td>31</td>\n",
       "      <td>63229</td>\n",
       "      <td>37791</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.257</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Nevada</td>\n",
       "      <td>NV</td>\n",
       "      <td>32</td>\n",
       "      <td>63276</td>\n",
       "      <td>41065</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.278</td>\n",
       "      <td>0.246</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NewHampshire</td>\n",
       "      <td>NH</td>\n",
       "      <td>33</td>\n",
       "      <td>77933</td>\n",
       "      <td>45803</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.281</td>\n",
       "      <td>0.178</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.229</td>\n",
       "      <td>0.147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>NewJersey</td>\n",
       "      <td>NJ</td>\n",
       "      <td>34</td>\n",
       "      <td>85751</td>\n",
       "      <td>49643</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.269</td>\n",
       "      <td>0.157</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.251</td>\n",
       "      <td>0.161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>NewMexico</td>\n",
       "      <td>NM</td>\n",
       "      <td>35</td>\n",
       "      <td>51945</td>\n",
       "      <td>32958</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.264</td>\n",
       "      <td>0.227</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>NewYork</td>\n",
       "      <td>NY</td>\n",
       "      <td>36</td>\n",
       "      <td>72108</td>\n",
       "      <td>44681</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.258</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>NorthCarolina</td>\n",
       "      <td>NC</td>\n",
       "      <td>37</td>\n",
       "      <td>57341</td>\n",
       "      <td>34864</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.256</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>NorthDakota</td>\n",
       "      <td>ND</td>\n",
       "      <td>38</td>\n",
       "      <td>64577</td>\n",
       "      <td>38698</td>\n",
       "      <td>0.113</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.267</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Ohio</td>\n",
       "      <td>OH</td>\n",
       "      <td>39</td>\n",
       "      <td>58642</td>\n",
       "      <td>35147</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.326</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Oklahoma</td>\n",
       "      <td>OK</td>\n",
       "      <td>40</td>\n",
       "      <td>54449</td>\n",
       "      <td>32185</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.228</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Oregon</td>\n",
       "      <td>OR</td>\n",
       "      <td>41</td>\n",
       "      <td>67058</td>\n",
       "      <td>41733</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.248</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>PA</td>\n",
       "      <td>42</td>\n",
       "      <td>63463</td>\n",
       "      <td>36748</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.344</td>\n",
       "      <td>0.157</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>RhodeIsland</td>\n",
       "      <td>RI</td>\n",
       "      <td>44</td>\n",
       "      <td>71169</td>\n",
       "      <td>40254</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.284</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.209</td>\n",
       "      <td>0.139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>SouthCarolina</td>\n",
       "      <td>SC</td>\n",
       "      <td>45</td>\n",
       "      <td>56227</td>\n",
       "      <td>33610</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.285</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>SouthDakota</td>\n",
       "      <td>SD</td>\n",
       "      <td>46</td>\n",
       "      <td>59533</td>\n",
       "      <td>35697</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Tennessee</td>\n",
       "      <td>TN</td>\n",
       "      <td>47</td>\n",
       "      <td>56071</td>\n",
       "      <td>33992</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Texas</td>\n",
       "      <td>TX</td>\n",
       "      <td>48</td>\n",
       "      <td>64034</td>\n",
       "      <td>40389</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.252</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Utah</td>\n",
       "      <td>UT</td>\n",
       "      <td>49</td>\n",
       "      <td>75780</td>\n",
       "      <td>42659</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.231</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.234</td>\n",
       "      <td>0.113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Vermont</td>\n",
       "      <td>VT</td>\n",
       "      <td>50</td>\n",
       "      <td>63001</td>\n",
       "      <td>38034</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.227</td>\n",
       "      <td>0.160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Virginia</td>\n",
       "      <td>VA</td>\n",
       "      <td>51</td>\n",
       "      <td>76456</td>\n",
       "      <td>46570</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.236</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Washington</td>\n",
       "      <td>WA</td>\n",
       "      <td>53</td>\n",
       "      <td>78687</td>\n",
       "      <td>50045</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.227</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.228</td>\n",
       "      <td>0.142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>WestVirginia</td>\n",
       "      <td>WV</td>\n",
       "      <td>54</td>\n",
       "      <td>48850</td>\n",
       "      <td>26752</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.402</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>WI</td>\n",
       "      <td>55</td>\n",
       "      <td>64168</td>\n",
       "      <td>38937</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.305</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>WY</td>\n",
       "      <td>56</td>\n",
       "      <td>65003</td>\n",
       "      <td>37299</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.301</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.113</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            State STATE_ABB FIPS  MedianHouseholdIncome  \\\n",
       "0         Alabama        AL   01                  51734   \n",
       "1          Alaska        AK   02                  75463   \n",
       "2         Arizona        AZ   04                  62055   \n",
       "3        Arkansas        AR   05                  48952   \n",
       "4      California        CA   06                  80440   \n",
       "5        Colorado        CO   08                  77127   \n",
       "6     Connecticut        CT   09                  78833   \n",
       "7        Delaware        DE   10                  70176   \n",
       "8              DC        DC   11                  92266   \n",
       "9         Florida        FL   12                  59227   \n",
       "10        Georgia        GA   13                  61980   \n",
       "11         Hawaii        HI   15                  83102   \n",
       "12          Idaho        ID   16                  60999   \n",
       "13       Illinois        IL   17                  69187   \n",
       "14        Indiana        IN   18                  57603   \n",
       "15           Iowa        IA   19                  61691   \n",
       "16         Kansas        KS   20                  62087   \n",
       "17       Kentucky        KY   21                  52295   \n",
       "18      Louisiana        LA   22                  51073   \n",
       "19          Maine        ME   23                  58924   \n",
       "20       Maryland        MD   24                  86738   \n",
       "21  Massachusetts        MA   25                  85843   \n",
       "22       Michigan        MI   26                  59584   \n",
       "23      Minnesota        MN   27                  74593   \n",
       "24    Mississippi        MS   28                  45792   \n",
       "25       Missouri        MO   29                  57409   \n",
       "26        Montana        MT   30                  57153   \n",
       "27       Nebraska        NE   31                  63229   \n",
       "28         Nevada        NV   32                  63276   \n",
       "29   NewHampshire        NH   33                  77933   \n",
       "30      NewJersey        NJ   34                  85751   \n",
       "31      NewMexico        NM   35                  51945   \n",
       "32        NewYork        NY   36                  72108   \n",
       "33  NorthCarolina        NC   37                  57341   \n",
       "34    NorthDakota        ND   38                  64577   \n",
       "35           Ohio        OH   39                  58642   \n",
       "36       Oklahoma        OK   40                  54449   \n",
       "37         Oregon        OR   41                  67058   \n",
       "38   Pennsylvania        PA   42                  63463   \n",
       "39    RhodeIsland        RI   44                  71169   \n",
       "40  SouthCarolina        SC   45                  56227   \n",
       "41    SouthDakota        SD   46                  59533   \n",
       "42      Tennessee        TN   47                  56071   \n",
       "43          Texas        TX   48                  64034   \n",
       "44           Utah        UT   49                  75780   \n",
       "45        Vermont        VT   50                  63001   \n",
       "46       Virginia        VA   51                  76456   \n",
       "47     Washington        WA   53                  78687   \n",
       "48   WestVirginia        WV   54                  48850   \n",
       "49      Wisconsin        WI   55                  64168   \n",
       "50        Wyoming        WY   56                  65003   \n",
       "\n",
       "    MedianNonfamilyIncome  Pct18to64InPoverty  PctOver65InPoverty  \\\n",
       "0                   29458               0.147               0.105   \n",
       "1                   47508               0.095               0.069   \n",
       "2                   40198               0.127               0.090   \n",
       "3                   27607               0.155               0.105   \n",
       "4                   51676               0.107               0.105   \n",
       "5                   50092               0.093               0.072   \n",
       "6                   45001               0.094               0.073   \n",
       "7                   44071               0.108               0.073   \n",
       "8                   76529               0.120               0.133   \n",
       "9                   37292               0.117               0.107   \n",
       "10                  37881               0.119               0.104   \n",
       "11                  51343               0.085               0.087   \n",
       "12                  35157               0.115               0.069   \n",
       "13                  40860               0.107               0.086   \n",
       "14                  33994               0.118               0.077   \n",
       "15                  36559               0.116               0.074   \n",
       "16                  36347               0.112               0.072   \n",
       "17                  30384               0.155               0.116   \n",
       "18                  28907               0.174               0.132   \n",
       "19                  35624               0.108               0.085   \n",
       "20                  51990               0.083               0.078   \n",
       "21                  50338               0.088               0.091   \n",
       "22                  35755               0.127               0.084   \n",
       "23                  44136               0.085               0.074   \n",
       "24                  25562               0.180               0.132   \n",
       "25                  33821               0.125               0.089   \n",
       "26                  34919               0.132               0.086   \n",
       "27                  37791               0.099               0.081   \n",
       "28                  41065               0.117               0.095   \n",
       "29                  45803               0.076               0.062   \n",
       "30                  49643               0.081               0.088   \n",
       "31                  32958               0.170               0.135   \n",
       "32                  44681               0.116               0.120   \n",
       "33                  34864               0.127               0.091   \n",
       "34                  38698               0.113               0.080   \n",
       "35                  35147               0.124               0.083   \n",
       "36                  32185               0.147               0.097   \n",
       "37                  41733               0.118               0.081   \n",
       "38                  36748               0.115               0.083   \n",
       "39                  40254               0.104               0.089   \n",
       "40                  33610               0.129               0.101   \n",
       "41                  35697               0.119               0.077   \n",
       "42                  33992               0.129               0.097   \n",
       "43                  40389               0.119               0.106   \n",
       "44                  42659               0.089               0.062   \n",
       "45                  38034               0.115               0.061   \n",
       "46                  46570               0.094               0.071   \n",
       "47                  50045               0.096               0.075   \n",
       "48                  26752               0.170               0.093   \n",
       "49                  38937               0.102               0.074   \n",
       "50                  37299               0.103               0.074   \n",
       "\n",
       "    PctUnemployedCivilians  PctLessThan9thGrade  Pct9thto12thGrade  PctHSGrad  \\\n",
       "0                    0.049                0.039              0.090      0.309   \n",
       "1                    0.058                0.022              0.043      0.287   \n",
       "2                    0.051                0.051              0.073      0.237   \n",
       "3                    0.048                0.046              0.079      0.349   \n",
       "4                    0.051                0.087              0.073      0.206   \n",
       "5                    0.037                0.032              0.044      0.210   \n",
       "6                    0.053                0.040              0.053      0.268   \n",
       "7                    0.046                0.035              0.062      0.302   \n",
       "8                    0.063                0.033              0.049      0.158   \n",
       "9                    0.045                0.046              0.070      0.284   \n",
       "10                   0.048                0.045              0.076      0.274   \n",
       "11                   0.039                0.036              0.040      0.274   \n",
       "12                   0.033                0.030              0.055      0.261   \n",
       "13                   0.048                0.045              0.057      0.259   \n",
       "14                   0.042                0.036              0.068      0.339   \n",
       "15                   0.037                0.027              0.046      0.310   \n",
       "16                   0.038                0.033              0.049      0.263   \n",
       "17                   0.048                0.051              0.077      0.332   \n",
       "18                   0.055                0.044              0.096      0.339   \n",
       "19                   0.035                0.021              0.047      0.314   \n",
       "20                   0.045                0.040              0.056      0.246   \n",
       "21                   0.039                0.042              0.045      0.239   \n",
       "22                   0.050                0.027              0.060      0.291   \n",
       "23                   0.032                0.027              0.037      0.244   \n",
       "24                   0.066                0.046              0.101      0.302   \n",
       "25                   0.038                0.029              0.064      0.311   \n",
       "26                   0.041                0.016              0.041      0.284   \n",
       "27                   0.033                0.034              0.045      0.257   \n",
       "28                   0.051                0.051              0.080      0.278   \n",
       "29                   0.030                0.020              0.047      0.281   \n",
       "30                   0.047                0.047              0.050      0.269   \n",
       "31                   0.055                0.058              0.083      0.264   \n",
       "32                   0.044                0.058              0.066      0.258   \n",
       "33                   0.046                0.042              0.072      0.256   \n",
       "34                   0.026                0.026              0.039      0.267   \n",
       "35                   0.046                0.027              0.065      0.326   \n",
       "36                   0.044                0.039              0.077      0.315   \n",
       "37                   0.050                0.033              0.054      0.230   \n",
       "38                   0.045                0.030              0.060      0.344   \n",
       "39                   0.042                0.050              0.057      0.284   \n",
       "40                   0.047                0.037              0.079      0.285   \n",
       "41                   0.030                0.028              0.051      0.300   \n",
       "42                   0.045                0.043              0.077      0.315   \n",
       "43                   0.044                0.077              0.077      0.252   \n",
       "44                   0.032                0.024              0.045      0.231   \n",
       "45                   0.034                0.021              0.048      0.290   \n",
       "46                   0.040                0.038              0.062      0.236   \n",
       "47                   0.046                0.035              0.048      0.221   \n",
       "48                   0.060                0.042              0.087      0.402   \n",
       "49                   0.032                0.025              0.048      0.305   \n",
       "50                   0.036                0.017              0.038      0.301   \n",
       "\n",
       "    PctSomeCollege  PctAssociatesDeg  PctBachelorsDeg  PctGradDeg  \n",
       "0            0.208             0.090            0.163       0.100  \n",
       "1            0.257             0.090            0.185       0.117  \n",
       "2            0.250             0.087            0.188       0.113  \n",
       "3            0.218             0.075            0.151       0.083  \n",
       "4            0.206             0.079            0.219       0.131  \n",
       "5            0.203             0.084            0.266       0.160  \n",
       "6            0.165             0.076            0.220       0.178  \n",
       "7            0.186             0.083            0.195       0.137  \n",
       "8            0.130             0.033            0.257       0.340  \n",
       "9            0.194             0.099            0.193       0.114  \n",
       "10           0.200             0.080            0.199       0.126  \n",
       "11           0.207             0.106            0.221       0.116  \n",
       "12           0.260             0.106            0.188       0.099  \n",
       "13           0.200             0.082            0.217       0.141  \n",
       "14           0.199             0.088            0.173       0.097  \n",
       "15           0.204             0.119            0.198       0.095  \n",
       "16           0.224             0.090            0.216       0.124  \n",
       "17           0.203             0.085            0.149       0.103  \n",
       "18           0.206             0.064            0.160       0.089  \n",
       "19           0.186             0.100            0.208       0.124  \n",
       "20           0.180             0.069            0.218       0.191  \n",
       "21           0.150             0.074            0.247       0.203  \n",
       "22           0.228             0.094            0.182       0.119  \n",
       "23           0.204             0.115            0.245       0.127  \n",
       "24           0.223             0.105            0.137       0.086  \n",
       "25           0.214             0.079            0.184       0.118  \n",
       "26           0.229             0.094            0.231       0.105  \n",
       "27           0.220             0.111            0.218       0.114  \n",
       "28           0.246             0.088            0.167       0.090  \n",
       "29           0.178             0.099            0.229       0.147  \n",
       "30           0.157             0.064            0.251       0.161  \n",
       "31           0.227             0.091            0.155       0.122  \n",
       "32           0.152             0.088            0.212       0.166  \n",
       "33           0.206             0.101            0.205       0.118  \n",
       "34           0.224             0.140            0.215       0.089  \n",
       "35           0.201             0.087            0.182       0.111  \n",
       "36           0.228             0.079            0.171       0.091  \n",
       "37           0.248             0.090            0.210       0.135  \n",
       "38           0.157             0.086            0.195       0.128  \n",
       "39           0.174             0.086            0.209       0.139  \n",
       "40           0.204             0.099            0.184       0.112  \n",
       "41           0.205             0.119            0.206       0.091  \n",
       "42           0.203             0.074            0.180       0.107  \n",
       "43           0.212             0.075            0.200       0.108  \n",
       "44           0.255             0.097            0.234       0.113  \n",
       "45           0.167             0.087            0.227       0.160  \n",
       "46           0.189             0.080            0.224       0.172  \n",
       "47           0.227             0.100            0.228       0.142  \n",
       "48           0.179             0.079            0.126       0.084  \n",
       "49           0.200             0.109            0.207       0.107  \n",
       "50           0.240             0.113            0.188       0.104  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make an empty dataframe\n",
    "acs_final_df = create_df()\n",
    "\n",
    "# Directory path\n",
    "my_dir = '/Users/darionguan/Desktop/Presidential Prediction/ACS/'\n",
    "\n",
    "# # For every file in lst\n",
    "# for filename in os.listdir(my_dir):\n",
    "#     # If the file ends with name of state that has 1 CD\n",
    "#     # Last statement used to dodge .DS_Store file\n",
    "#     if (filename.endswith('Alaska.csv') or filename.endswith('Delaware.csv') or filename.endswith('DC.csv') \\\n",
    "#     or filename.endswith('Montana.csv') or filename.endswith('NorthDakota.csv') \\\n",
    "#     or filename.endswith('SouthDakota.csv') or filename.endswith('Vermont.csv') \\\n",
    "#     or filename.endswith('Wyoming.csv')) and filename.startswith('.') is False:\n",
    "#         # state_name variable to be used in read_one_cd() function\n",
    "#         state_name = file_to_state(filename)\n",
    "#         # Use function for reading 1 CD state\n",
    "#         acs_df = read_one_state(my_dir + filename, state_name)\n",
    "#         # Concatenate working acs_df to acs_final_df\n",
    "#         acs_final_df = pd.concat([acs_final_df, acs_df], ignore_index=True)\n",
    "        \n",
    "#     # Else - statement used to dodge .DS_Store file\n",
    "#     elif filename.startswith('.') is False:\n",
    "#         # Use file_to_state() to find state name from filename\n",
    "#         # Use state name as key to find corresponding number of CDs in state_dict\n",
    "#         # Create an array to be used as number of cols read from csv\n",
    "#         cols = new_arr(state_dict[file_to_state(filename)])\n",
    "#         # state_name variable to be used in read_multi_cd() function\n",
    "#         state_name = file_to_state(filename)\n",
    "#         # Use function for reading multi-CD state\n",
    "#         acs_df = read_multi_state(my_dir + filename, cols, state_name)\n",
    "#         # Concatenate working acs_df to acs_final_df\n",
    "#         acs_final_df = pd.concat([acs_final_df, acs_df], ignore_index=True)\n",
    "\n",
    "acs_final_df = loop_states()\n",
    "\n",
    "# Sort by columns\n",
    "acs_final_df = acs_final_df.sort_values(by='FIPS', ascending=True)\n",
    "\n",
    "# Drop CD column\n",
    "acs_final_df = acs_final_df.drop('CD', axis=1)\n",
    "\n",
    "# Reindex\n",
    "acs_final_df = acs_final_df.reset_index(drop=True)\n",
    "\n",
    "# Convert dtypes\n",
    "acs_final_df = acs_final_df.astype({'Median household income': 'int64',\n",
    "                                    'Median nonfamily income': 'int64',\n",
    "                                    'Persons aged 18 to 64 in poverty': 'float64',\n",
    "                                    'Persons over 65 in poverty': 'float64',\n",
    "                                    'Unemployed civilians': 'float64',\n",
    "                                    'Less than 9th grade': 'float64',\n",
    "                                    '9th to 12th grade, no diploma': 'float64',\n",
    "                                    'High school graduate (includes equivalency)': 'float64',\n",
    "                                    'Some college, no degree': 'float64',\n",
    "                                    'Associates degree': 'float64',\n",
    "                                    'Bachelors degree': 'float64',\n",
    "                                    'Graduate or professional degree': 'float64'})\n",
    "\n",
    "# Rename columns\n",
    "acs_final_df = acs_final_df.rename(columns={acs_final_df.columns[3]: 'MedianHouseholdIncome',\n",
    "                                            acs_final_df.columns[4]: 'MedianNonfamilyIncome',\n",
    "                                            acs_final_df.columns[5]: 'Pct18to64InPoverty',\n",
    "                                            acs_final_df.columns[6]: 'PctOver65InPoverty',\n",
    "                                            acs_final_df.columns[7]: 'PctUnemployedCivilians',\n",
    "                                            acs_final_df.columns[8]: 'PctLessThan9thGrade',\n",
    "                                            acs_final_df.columns[9]: 'Pct9thto12thGrade',\n",
    "                                            acs_final_df.columns[10]: 'PctHSGrad',\n",
    "                                            acs_final_df.columns[11]: 'PctSomeCollege',\n",
    "                                            acs_final_df.columns[12]: 'PctAssociatesDeg',\n",
    "                                            acs_final_df.columns[13]: 'PctBachelorsDeg',\n",
    "                                            acs_final_df.columns[14]: 'PctGradDeg'})\n",
    "\n",
    "# Convert percentages to decimal\n",
    "acs_final_df['Pct18to64InPoverty'] = acs_final_df['Pct18to64InPoverty'] / 100\n",
    "acs_final_df['PctOver65InPoverty'] = acs_final_df['PctOver65InPoverty'] / 100\n",
    "acs_final_df['PctUnemployedCivilians'] = acs_final_df['PctUnemployedCivilians'] / 100\n",
    "acs_final_df['PctLessThan9thGrade'] = acs_final_df['PctLessThan9thGrade'] / 100\n",
    "acs_final_df['Pct9thto12thGrade'] = acs_final_df['Pct9thto12thGrade'] / 100\n",
    "acs_final_df['PctHSGrad'] = acs_final_df['PctHSGrad'] / 100\n",
    "acs_final_df['PctSomeCollege'] = acs_final_df['PctSomeCollege'] / 100\n",
    "acs_final_df['PctAssociatesDeg'] = acs_final_df['PctAssociatesDeg'] / 100\n",
    "acs_final_df['PctBachelorsDeg'] = acs_final_df['PctBachelorsDeg'] / 100\n",
    "acs_final_df['PctGradDeg'] = acs_final_df['PctGradDeg'] / 100\n",
    "\n",
    "# Convert df to csv\n",
    "acs_final_df.to_csv('acs_state_final.csv')\n",
    "\n",
    "acs_final_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
